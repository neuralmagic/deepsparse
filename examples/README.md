<!--
Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

# Examples

This directory contains self-documented examples to illustrate how to make use of the DeepSparse Engine. 

For instructions on how to run each example, either check the script README or run them with `-h`.

Open a Pull Request to [contribute](https://github.com/neuralmagic/deepsparse/blob/main/CONTRIBUTING.md) your own examples.

## Examples

| Notebook     |      Description      |
|----------|-------------|
| [Benchmark and ONNX Model Correctness](https://github.com/neuralmagic/deepsparse/tree/main/examples/benchmark/)  | Comparing predictions and benchmark performance between DeepSparse Engine and ONNXRuntime.  |
| [Hugging Face Transformers](https://github.com/neuralmagic/deepsparse/tree/main/examples/huggingface-transformers/) | Serving, benchmarking, and running NLP models from Hugging Face. |
| [YOLOv3 and YOLOv5](https://github.com/neuralmagic/deepsparse/tree/main/examples/ultralytics-yolo/) | Serving, benchmarking, and running annotation inferences with YOLOv3 and YOLOv5 models. |
| [Image Classification](https://github.com/neuralmagic/deepsparse/tree/main/examples/classification/)  | How to use image classification models from SparseZoo to perform inference and benchmarking with the DeepSparse Engine.  |
| [Object Detection](https://github.com/neuralmagic/deepsparse/tree/main/examples/detection/)  | How to use object detection models from SparseZoo to perform inference and benchmarking with the DeepSparse Engine.  |
| [Instance Segmentation](https://github.com/neuralmagic/deepsparse/tree/main/examples/dbolya-yolact/)  | How to use an optimized YOLACT model and the DeepSparse Engine to perform real-time instance segmentation. |
| [AWS Lambda Integration](https://github.com/neuralmagic/deepsparse/tree/main/examples/aws-lambda/)  | How to deploy a DeepSparse pipeline on AWS Lambda. |
| [AWS Sagemaker Integration](https://github.com/neuralmagic/deepsparse/tree/main/examples/aws-sagemaker/)  | How to deploy a DeepSparse inference server on SageMaker. |
| [Google Kubernetes Engine](https://github.com/neuralmagic/deepsparse/tree/main/examples/google-kubernetes-engine/) | How to deploy a DeepSparse inference server on GKE. |
| [SparseStream](https://github.com/neuralmagic/deepsparse/tree/main/examples/sparsestream/)  | Deploying 2 sparse transformers for classifying Finance tweets in a real-time Twitter stream. |
| [SparseServer.UI](https://github.com/neuralmagic/deepsparse/tree/main/examples/sparseserver-ui/)  | A Streamlit app for deploying the DeepSparse Server to compare the latency and accuracy of sparse BERT models. |
| [Twitter Sentiment Analysis](https://github.com/neuralmagic/deepsparse/tree/main/examples/twitter-nlp/)  | Example of scraping, processing, and classifying Twitter data using the DeepSparse Engine for 10x faster performance on CPUs. |
| [Flask Model Server](https://github.com/neuralmagic/deepsparse/tree/main/examples/flask/)  | Simple model server and client example, showing how to use the DeepSparse Engine as an inference backend for a real-time inference server. |


